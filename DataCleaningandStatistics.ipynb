{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3801f667-095e-40af-9924-bfe88241ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned file to: C:\\Users\\avi04\\Downloads\\city_day_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "ZIP_PATH = r\"C:\\Users\\avi04\\Downloads\\air_quality_dataset (1).zip\"\n",
    "EXTRACT_DIR = r\"C:\\Users\\avi04\\Downloads\\air_quality_dataset\"\n",
    "INPUT_FILE = os.path.join(EXTRACT_DIR, \"city_day.csv\")\n",
    "OUTPUT_FILE = r\"C:\\Users\\avi04\\Downloads\\city_day_cleaned.csv\"\n",
    "\n",
    "POLLUTANTS = ['PM2.5','PM10','NO','NO2','NOx','NH3','CO','SO2','O3']\n",
    "VOCs = ['Benzene','Toluene','Xylene']\n",
    "GLOBAL_FALLBACK_COLS = ['PM10','NOx','NH3','O3']\n",
    "\n",
    "def extract_zip(zip_path, extract_dir):\n",
    "    if not os.path.exists(extract_dir):\n",
    "        os.makedirs(extract_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_dir)\n",
    "\n",
    "def clean_city_day(df):\n",
    "    df = df.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    for col in POLLUTANTS + VOCs:\n",
    "        if col in df.columns:\n",
    "            df[col] = df.groupby(\"City\")[col].transform(lambda x: x.fillna(x.median()))\n",
    "    for col in GLOBAL_FALLBACK_COLS:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    df = df.drop(columns=[\"AQI\",\"AQI_Bucket\"], errors=\"ignore\")\n",
    "    cols = df.columns.tolist()\n",
    "    ordered = [\"City\",\"Date\"] + [c for c in cols if c not in [\"City\",\"Date\"]]\n",
    "    return df[ordered]\n",
    "\n",
    "def main():\n",
    "    extract_zip(ZIP_PATH, EXTRACT_DIR)\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    cleaned = clean_city_day(df)\n",
    "    cleaned.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(\"Saved cleaned file to:\", OUTPUT_FILE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1390d1f-bddd-4f07-b295-32135fa382ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI calculation complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\avi04\\Downloads\\city_day_cleaned.csv\")\n",
    "\n",
    "def compute_subindex(C, breakpoints):\n",
    "    for BPlo, BPhi, Ilo, Ihi in breakpoints:\n",
    "        if BPlo <= C <= BPhi:\n",
    "            return ((Ihi - Ilo) / (BPhi - BPlo)) * (C - BPlo) + Ilo\n",
    "    return np.nan\n",
    "\n",
    "pm25_bp = [\n",
    "    (0, 30, 0, 50),\n",
    "    (31, 60, 51, 100),\n",
    "    (61, 90, 101, 200),\n",
    "    (91, 120, 201, 300),\n",
    "    (121, 250, 301, 400),\n",
    "    (251, 500, 401, 500)\n",
    "]\n",
    "\n",
    "pm10_bp = [\n",
    "    (0, 50, 0, 50),\n",
    "    (51, 100, 51, 100),\n",
    "    (101, 250, 101, 200),\n",
    "    (251, 350, 201, 300),\n",
    "    (351, 430, 301, 400),\n",
    "    (430, 1000, 401, 500)\n",
    "]\n",
    "\n",
    "no2_bp = [\n",
    "    (0, 40, 0, 50),\n",
    "    (41, 80, 51, 100),\n",
    "    (81, 180, 101, 200),\n",
    "    (181, 280, 201, 300),\n",
    "    (281, 400, 301, 400),\n",
    "    (401, 1000, 401, 500)\n",
    "]\n",
    "\n",
    "so2_bp = [\n",
    "    (0, 40, 0, 50),\n",
    "    (41, 80, 51, 100),\n",
    "    (81, 380, 101, 200),\n",
    "    (381, 800, 201, 300),\n",
    "    (801, 1600, 301, 400),\n",
    "    (1601, 2000, 401, 500)\n",
    "]\n",
    "\n",
    "co_bp = [\n",
    "    (0, 1, 0, 50),\n",
    "    (1, 2, 51, 100),\n",
    "    (2, 10, 101, 200),\n",
    "    (10, 17, 201, 300),\n",
    "    (17, 34, 301, 400),\n",
    "    (34, 50, 401, 500)\n",
    "]\n",
    "\n",
    "o3_bp = [\n",
    "    (0, 50, 0, 50),\n",
    "    (51, 100, 51, 100),\n",
    "    (101, 168, 101, 200),\n",
    "    (169, 208, 201, 300),\n",
    "    (209, 748, 301, 400),\n",
    "    (749, 1000, 401, 500)\n",
    "]\n",
    "\n",
    "df[\"SI_PM25\"] = df[\"PM2.5\"].apply(lambda x: compute_subindex(x, pm25_bp))\n",
    "df[\"SI_PM10\"] = df[\"PM10\"].apply(lambda x: compute_subindex(x, pm10_bp))\n",
    "df[\"SI_NO2\"] = df[\"NO2\"].apply(lambda x: compute_subindex(x, no2_bp))\n",
    "df[\"SI_SO2\"] = df[\"SO2\"].apply(lambda x: compute_subindex(x, so2_bp))\n",
    "df[\"SI_CO\"] = df[\"CO\"].apply(lambda x: compute_subindex(x, co_bp))\n",
    "df[\"SI_O3\"] = df[\"O3\"].apply(lambda x: compute_subindex(x, o3_bp))\n",
    "\n",
    "df[\"AQI\"] = df[[\"SI_PM25\",\"SI_PM10\",\"SI_NO2\",\"SI_SO2\",\"SI_CO\",\"SI_O3\"]].max(axis=1)\n",
    "\n",
    "def bucket(aqi):\n",
    "    if aqi <= 50: return \"Good\"\n",
    "    elif aqi <= 100: return \"Satisfactory\"\n",
    "    elif aqi <= 200: return \"Moderate\"\n",
    "    elif aqi <= 300: return \"Poor\"\n",
    "    elif aqi <= 400: return \"Very Poor\"\n",
    "    else: return \"Severe\"\n",
    "\n",
    "df[\"AQI_Bucket\"] = df[\"AQI\"].apply(bucket)\n",
    "\n",
    "df.to_csv(r\"C:\\Users\\avi04\\Downloads\\city_day_with_AQI.csv\", index=False)\n",
    "\n",
    "print(\"AQI calculation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f529db2c-38fb-4989-8334-89b107ad5642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics:\n",
      "\n",
      "             mean   median   min      max     mode\n",
      "PM2.5   64.495018   48.170  0.04   949.99   23.745\n",
      "PM10   111.529814  100.685  0.01  1000.00  100.685\n",
      "NO      17.586426   10.580  0.02   390.68   25.340\n",
      "NO2     28.038496   21.460  0.01   362.21   21.460\n",
      "NOx     31.738348   24.290  0.00   467.63   24.290\n",
      "NH3     21.785599   14.500  0.01   352.89   14.500\n",
      "CO       2.469716    0.900  0.00   175.81    0.000\n",
      "SO2     15.120249    9.900  0.01   193.86   12.670\n",
      "O3      33.794051   29.620  0.01   257.73   29.620\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\avi04\\Downloads\\city_day_with_AQI.csv\")\n",
    "\n",
    "pollutants = [\"PM2.5\",\"PM10\",\"NO\",\"NO2\",\"NOx\",\"NH3\",\"CO\",\"SO2\",\"O3\"]\n",
    "\n",
    "# Basic descriptive statistics\n",
    "desc_stats = df[pollutants].agg([\"mean\", \"median\", \"min\", \"max\"]).T\n",
    "\n",
    "# Mode for each pollutant\n",
    "mode_stats = df[pollutants].mode().iloc[0]\n",
    "\n",
    "desc_stats[\"mode\"] = mode_stats\n",
    "\n",
    "print(\"Descriptive Statistics:\\n\")\n",
    "print(desc_stats)\n",
    "\n",
    "desc_stats.to_csv(r\"C:\\Users\\avi04\\Downloads\\descriptive_statistics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b94e55-e278-4da0-909f-51fa365f105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dominant pollutant per city:\n",
      "\n",
      "City\n",
      "Ahmedabad               CO\n",
      "Aizawl                PM25\n",
      "Amaravati             PM10\n",
      "Amritsar              PM10\n",
      "Bengaluru             PM10\n",
      "Bhopal                PM10\n",
      "Brajrajnagar          PM10\n",
      "Chandigarh            PM10\n",
      "Chennai               PM25\n",
      "Coimbatore              CO\n",
      "Delhi                 PM25\n",
      "Ernakulam               CO\n",
      "Gurugram              PM25\n",
      "Guwahati              PM25\n",
      "Hyderabad             PM10\n",
      "Jaipur                PM10\n",
      "Jorapokhar            PM10\n",
      "Kochi                   CO\n",
      "Kolkata               PM10\n",
      "Lucknow               PM25\n",
      "Mumbai                PM10\n",
      "Patna                 PM25\n",
      "Shillong              PM25\n",
      "Talcher               PM10\n",
      "Thiruvananthapuram      CO\n",
      "Visakhapatnam         PM10\n",
      "Name: Dominant_Pollutant, dtype: object\n"
     ]
    }
   ],
   "source": [
    "subindex_cols = [\"SI_PM25\",\"SI_PM10\",\"SI_NO2\",\"SI_SO2\",\"SI_CO\",\"SI_O3\"]\n",
    "\n",
    "def dominant_pollutant(row):\n",
    "    return row[subindex_cols].idxmax().replace(\"SI_\", \"\")\n",
    "\n",
    "df[\"Dominant_Pollutant\"] = df.apply(dominant_pollutant, axis=1)\n",
    "\n",
    "city_dom = df.groupby(\"City\")[\"Dominant_Pollutant\"].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "city_dom.to_csv(r\"C:\\Users\\avi04\\Downloads\\dominant_pollutant_city.csv\")\n",
    "\n",
    "print(\"\\nDominant pollutant per city:\\n\")\n",
    "print(city_dom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0033dda-5c4d-434a-b7f3-a454722188b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 29531, Unparsed date rows: 0\n",
      "Saved parsed dataset to: C:\\Users\\avi04\\Downloads\\city_day_cleaned_dates_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:\\Users\\avi04\\Downloads\\city_day_cleaned.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Try parsing robustly: first try dayfirst, then fall back with errors='coerce'\n",
    "# Use parse_dates on the column if you prefer; here we attempt two passes for robustness.\n",
    "def parse_dates_try(col):\n",
    "    # 1) try fast parse with dayfirst\n",
    "    parsed = pd.to_datetime(col, dayfirst=True, errors='coerce')\n",
    "    # 2) where parse failed, try without dayfirst (ISO-ish)\n",
    "    mask_failed = parsed.isna()\n",
    "    if mask_failed.any():\n",
    "        parsed2 = pd.to_datetime(col[mask_failed], dayfirst=False, errors='coerce')\n",
    "        parsed.loc[mask_failed] = parsed2\n",
    "    return parsed\n",
    "\n",
    "df['Date_parsed'] = parse_dates_try(df['Date'])\n",
    "\n",
    "# Report failures\n",
    "n_failed = df['Date_parsed'].isna().sum()\n",
    "print(f\"Total rows: {len(df)}, Unparsed date rows: {n_failed}\")\n",
    "\n",
    "if n_failed > 0:\n",
    "    print(\"Sample of rows with unparsed Date values:\")\n",
    "    display(df.loc[df['Date_parsed'].isna(), ['Date']].drop_duplicates().head(20))\n",
    "\n",
    "# If you prefer to see their indices/rows:\n",
    "# display(df[df['Date_parsed'].isna()].head(10))\n",
    "\n",
    "# If many are NaT you can decide to drop or inspect. For now we'll keep and create Year/Month with NaNs handled.\n",
    "df['Date'] = df['Date_parsed']  # replace/overwrite original\n",
    "df = df.drop(columns=['Date_parsed'])\n",
    "\n",
    "# Create Year and Month columns (will be NaN for unparsed dates)\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "# Save a quick version for further work\n",
    "out_path = r\"C:\\Users\\avi04\\Downloads\\city_day_cleaned_dates_fixed.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved parsed dataset to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d816c9c5-a111-4b83-b8c6-852d9380662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"] = pd.to_datetime(df[\"Date\"]).dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d359624-2cf1-4929-98f4-5886fb7d889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        PM2.5        PM10         NO        NO2        NOx  \\\n",
      "City          Year                                                           \n",
      "Ahmedabad     2015  74.339918  107.960000  14.032000  25.446493  34.286164   \n",
      "              2016  59.780929  107.960000  15.804973  36.183470  35.454044   \n",
      "              2017  64.447288  107.960000  18.861205  52.753836  43.790712   \n",
      "              2018  74.599370  107.960000  33.151452  84.730658  60.317342   \n",
      "              2019  62.056849  115.538849  25.971863  90.369205  62.721123   \n",
      "...                       ...         ...        ...        ...        ...   \n",
      "Visakhapatnam 2016  44.697500   88.346630  16.461902  42.183261  32.574022   \n",
      "              2017  48.448767  104.437849  11.770301  34.602630  12.314521   \n",
      "              2018  49.894822  115.826808  12.341370  38.764466  30.248082   \n",
      "              2019  47.156055  114.403014  13.863370  37.672904  31.185288   \n",
      "              2020  32.104645   83.325355   6.679454  30.957432  21.623607   \n",
      "\n",
      "                          NH3         CO        SO2         O3  \n",
      "City          Year                                              \n",
      "Ahmedabad     2015  14.500000  14.026247  34.420685  32.711562  \n",
      "              2016  14.500000  15.781926  36.873716  33.387760  \n",
      "              2017  14.500000  18.832438  56.545288  41.973562  \n",
      "              2018  14.500000  33.151260  69.733836  39.708411  \n",
      "              2019  14.500000  25.971288  72.079507  46.452110  \n",
      "...                       ...        ...        ...        ...  \n",
      "Visakhapatnam 2016  13.291685   1.078696  21.227989  43.048098  \n",
      "              2017   9.689425   0.508877  10.365233  38.537863  \n",
      "              2018  12.043123   0.720959  11.182055  37.737918  \n",
      "              2019  10.198301   0.861014  12.892767  32.895315  \n",
      "              2020  10.407322   0.635956   8.216557  27.834317  \n",
      "\n",
      "[103 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "city_year_avg = df.groupby([\"City\",\"Year\"])[pollutants].mean()\n",
    "\n",
    "city_year_avg.to_csv(r\"C:\\Users\\avi04\\Downloads\\city_yearly_pollutant_avg.csv\")\n",
    "\n",
    "print(city_year_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764dcb1e-8a2b-4bdd-9124-9b6bd18c2c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQI_Bucket value counts:\n",
      " AQI_Bucket\n",
      "Satisfactory    10086\n",
      "Moderate         9493\n",
      "Poor             3178\n",
      "Very Poor        2995\n",
      "Good             2857\n",
      "Severe            922\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample rows with Date parsing issues (Date is NaT):\n",
      "Empty DataFrame\n",
      "Columns: [City, Date, PM2.5, PM10, NO, NO2, NOx, NH3, CO, SO2, O3, Benzene, Toluene, Xylene, Year, Month, SI_PM25, SI_PM10, SI_NO2, SI_SO2, SI_CO, SI_O3, AQI, AQI_Bucket]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 24 columns]\n",
      "\n",
      "Saved augmented file to: C:\\Users\\avi04\\Downloads\\city_day_descriptive_augmented.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:\\Users\\avi04\\Downloads\\city_day_cleaned.csv\"\n",
    "df = pd.read_csv(path, dtype=str)\n",
    "\n",
    "def try_parse_dates(s):\n",
    "    p = pd.to_datetime(s, dayfirst=True, errors='coerce')\n",
    "    mask = p.isna()\n",
    "    if mask.any():\n",
    "        p2 = pd.to_datetime(s[mask], dayfirst=False, errors='coerce')\n",
    "        p.loc[mask] = p2\n",
    "    return p\n",
    "\n",
    "df['Date'] = try_parse_dates(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "def compute_subindex_array(vals, breakpoints):\n",
    "    vals = pd.to_numeric(vals, errors='coerce').to_numpy(dtype=float)\n",
    "    out = np.full(vals.shape, np.nan)\n",
    "    for BPlo, BPhi, Ilo, Ihi in breakpoints:\n",
    "        mask = (vals >= BPlo) & (vals <= BPhi)\n",
    "        denom = (BPhi - BPlo) if (BPhi - BPlo) != 0 else 1\n",
    "        out[mask] = ((Ihi - Ilo) / denom) * (vals[mask] - BPlo) + Ilo\n",
    "    return out\n",
    "\n",
    "pm25_bp = [(0,30,0,50),(31,60,51,100),(61,90,101,200),(91,120,201,300),(121,250,301,400),(251,500,401,500)]\n",
    "pm10_bp = [(0,50,0,50),(51,100,51,100),(101,250,101,200),(251,350,201,300),(351,430,301,400),(431,10000,401,500)]\n",
    "no2_bp  = [(0,40,0,50),(41,80,51,100),(81,180,101,200),(181,280,201,300),(281,400,301,400),(401,10000,401,500)]\n",
    "so2_bp  = [(0,40,0,50),(41,80,51,100),(81,380,101,200),(381,800,201,300),(801,1600,301,400),(1601,10000,401,500)]\n",
    "co_bp   = [(0,1,0,50),(1.01,2,51,100),(2.01,10,101,200),(10.01,17,201,300),(17.01,34,301,400),(34.01,1000,401,500)]\n",
    "o3_bp   = [(0,50,0,50),(51,100,51,100),(101,168,101,200),(169,208,201,300),(209,748,301,400),(749,10000,401,500)]\n",
    "\n",
    "si_map = {\n",
    "    \"SI_PM25\": (\"PM2.5\", pm25_bp),\n",
    "    \"SI_PM10\": (\"PM10\", pm10_bp),\n",
    "    \"SI_NO2\": (\"NO2\", no2_bp),\n",
    "    \"SI_SO2\": (\"SO2\", so2_bp),\n",
    "    \"SI_CO\": (\"CO\", co_bp),\n",
    "    \"SI_O3\": (\"O3\", o3_bp)\n",
    "}\n",
    "\n",
    "for si_col, (poll_col, bp) in si_map.items():\n",
    "    if poll_col in df.columns and si_col not in df.columns:\n",
    "        df[si_col] = compute_subindex_array(df[poll_col], bp)\n",
    "\n",
    "si_cols = [c for c in df.columns if c.startswith(\"SI_\")]\n",
    "if len(si_cols) == 0:\n",
    "    raise RuntimeError(\"No SI_ columns created. Check pollutant column names.\")\n",
    "\n",
    "df['AQI'] = df[si_cols].apply(pd.to_numeric, errors='coerce').max(axis=1, skipna=True)\n",
    "\n",
    "def bucket_label(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "    if x <= 50: return \"Good\"\n",
    "    if x <= 100: return \"Satisfactory\"\n",
    "    if x <= 200: return \"Moderate\"\n",
    "    if x <= 300: return \"Poor\"\n",
    "    if x <= 400: return \"Very Poor\"\n",
    "    return \"Severe\"\n",
    "\n",
    "df['AQI_Bucket'] = df['AQI'].apply(bucket_label)\n",
    "\n",
    "print(\"AQI_Bucket value counts:\\n\", df['AQI_Bucket'].value_counts(dropna=True))\n",
    "print(\"\\nSample rows with Date parsing issues (Date is NaT):\")\n",
    "print(df[df['Date'].isna()].head(10))\n",
    "\n",
    "# optional: save augmented file\n",
    "out = r\"C:\\Users\\avi04\\Downloads\\city_day_descriptive_augmented.csv\"\n",
    "df.to_csv(out, index=False)\n",
    "print(\"\\nSaved augmented file to:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c72d79-a6e5-4cad-a767-c96869d5820a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
